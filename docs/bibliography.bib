@Article{genes11070717,
AUTHOR = {Abdulrauf Sharifai, Garba and Zainol, Zurinahni},
TITLE = {Feature Selection for High-Dimensional and Imbalanced Biomedical Data Based on Robust Correlation Based Redundancy and Binary Grasshopper Optimization Algorithm},
JOURNAL = {Genes},
VOLUME = {11},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {717},
URL = {https://www.mdpi.com/2073-4425/11/7/717},
ISSN = {2073-4425},
ABSTRACT = {The training machine learning algorithm from an imbalanced data set is an inherently challenging task. It becomes more demanding with limited samples but with a massive number of features (high dimensionality). The high dimensional and imbalanced data set has posed severe challenges in many real-world applications, such as biomedical data sets. Numerous researchers investigated either imbalanced class or high dimensional data sets and came up with various methods. Nonetheless, few approaches reported in the literature have addressed the intersection of the high dimensional and imbalanced class problem due to their complicated interactions. Lately, feature selection has become a well-known technique that has been used to overcome this problem by selecting discriminative features that represent minority and majority class. This paper proposes a new method called Robust Correlation Based Redundancy and Binary Grasshopper Optimization Algorithm (rCBR-BGOA); rCBR-BGOA has employed an ensemble of multi-filters coupled with the Correlation-Based Redundancy method to select optimal feature subsets. A binary Grasshopper optimisation algorithm (BGOA) is used to construct the feature selection process as an optimisation problem to select the best (near-optimal) combination of features from the majority and minority class. The obtained results, supported by the proper statistical analysis, indicate that rCBR-BGOA can improve the classification performance for high dimensional and imbalanced datasets in terms of G-mean and the Area Under the Curve (AUC) performance metrics.},
DOI = {10.3390/genes11070717}
}

@article{YIN20133,
title = {Feature selection for high-dimensional imbalanced data},
journal = {Neurocomputing},
volume = {105},
pages = {3-11},
year = {2013},
note = {Learning for Scalable Multimedia Representation},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.04.039},
url = {https://www.sciencedirect.com/science/article/pii/S0925231212007126},
author = {Liuzhi Yin and Yong Ge and Keli Xiao and Xuehua Wang and Xiaojun Quan},
keywords = {Feature selection, Imbalanced data, Hellinger distance, AUC, F-measure},
}

@ARTICLE{7339682,
author={B. {Xue} and M. {Zhang} and W. N. {Browne} and X. {Yao}},
journal={IEEE Transactions on Evolutionary Computation}, 
title={A Survey on Evolutionary Computation Approaches to Feature Selection}, 
year={2016},
volume={20},
number={4},
pages={606-626},
doi={10.1109/TEVC.2015.2504420}
}

@article{hallmark,
author = {Hall, Mark},
year = {2000},
month = {06},
pages = {},
title = {Correlation-Based Feature Selection for Machine Learning},
volume = {19},
journal = {Department of Computer Science}
}

@article{jamali2013,
author = {Jamali, Ilnaz and Bazmara, Mohammad and Jafari, Shahram},
year = {2013},
month = {05},
pages = {42},
title = {Feature Selection in Imbalance data sets},
volume = {9},
journal = {International Journal of Computer Science Issues}
}

@article{weissgary2003,
author = {Weiss, Gary and Provost, Foster},
year = {2003},
month = {07},
pages = {315-354},
title = {Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction},
volume = {19},
journal = {J. Artif. Intell. Res. (JAIR)},
doi = {10.1613/jair.1199}
}

@article{ziebapawel,
author = {Ziemba, Paweł},
year = {2012},
month = {},
pages = {221-236},
title = {Redukcja wymiarowości i selekcja cech w zadaniach klasyfikacji i regresji z wykorzystaniem uczenia maszynowego},
volume = {},
journal = {Zeszyty Naukowe Uniwersytetu Szczecińskiego. Studia Informatica},
}

@article{SOPHIAN200337,
title = {A feature extraction technique based on principal component analysis for pulsed Eddy current NDT},
journal = {NDT & E International},
volume = {36},
number = {1},
pages = {37-41},
year = {2003},
issn = {0963-8695},
doi = {https://doi.org/10.1016/S0963-8695(02)00069-5},
url = {https://www.sciencedirect.com/science/article/pii/S0963869502000695},
author = {Ali Sophian and Gui Yun Tian and David Taylor and John Rudlin},
keywords = {Pulsed Eddy current sensor, Feature extraction, Principal component analysis (PCA)},
abstract = {Pulsed Eddy current (PEC) is a new emerging NDT technique for sub-surface defect detection. The technique mainly uses the response peak value and arrival to detect and quantify the defects. This could suffer from noise and be not sufficient to extract more information about the defects, e.g. depth information of defects. This paper introduces the application of principal component analysis in extracting information from PEC responses. A comparative test carried out shows that the introduced technique has performed better than the conventional technique in the classification of defects.}
}

@article{Wasikowski2010CombatingTS,
  title={Combating the Small Sample Class Imbalance Problem Using Feature Selection},
  author={M. Wasikowski and Xue-wen Chen},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2010},
  volume={22},
  pages={1388-1400}
}

@inproceedings{TiwariDeepika,
author = {Tiwari, Deepika},
year = {2014},
month = {04},
pages = {},
title = {Handling Class Imbalance Problem Using Feature Selection}
}

@article{CoILDataMining,
author = {Elkan, Charles},
year = {2001},
month = {07},
pages = {},
title = {Magical Thinking in Data Mining: Lessons From CoIL Challenge 2000},
journal = {Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/502512.502576}
}

@article{GuyonIntroduction,
author = {Guyon, Isabelle and Elisseeff, André},
year = {2003},
month = {01},
pages = {1157 - 1182},
title = {An Introduction of Variable and Feature Selection},
volume = {3},
journal = {J. Machine Learning Research Special Issue on Variable and Feature Selection},
doi = {10.1162/153244303322753616}
}

@article{10.1016/j.engappai.2016.10.008,
author = {Moayedikia, Alireza and Ong, Kok-Leong and Boo, Yee Ling and Yeoh, William GS and Jensen, Richard},
title = {Feature Selection for High Dimensional Imbalanced Class Data Using Harmony Search},
year = {2017},
issue_date = {January 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {57},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2016.10.008},
doi = {10.1016/j.engappai.2016.10.008},
journal = {Eng. Appl. Artif. Intell.},
month = jan,
pages = {38–49},
numpages = {12},
keywords = {Feature selection, Harmony search, High-dimensionality, Symmetrical uncertainty, Imbalanced class}
}

@inbook{AwadMachine,
author = {Awad, Mariette and Khanna, Rahul},
year = {2015},
month = {01},
pages = {19-38},
title = {Machine Learning and Knowledge Discovery},
isbn = {978-1-4302-5989-3},
doi = {10.1007/978-1-4302-5990-9_2}
}

﻿@Article{Leevy2018,
author={Leevy, Joffrey L.
and Khoshgoftaar, Taghi M.
and Bauder, Richard A.
and Seliya, Naeem},
title={A survey on addressing high-class imbalance in big data},
journal={Journal of Big Data},
year={2018},
month={Nov},
day={01},
volume={5},
number={1},
pages={42},
issn={2196-1115},
doi={10.1186/s40537-018-0151-6},
url={https://doi.org/10.1186/s40537-018-0151-6}
}

@article{SILVA201624,
title = {An instance selection method for large datasets based on Markov Geometric Diffusion},
journal = {Data & Knowledge Engineering},
volume = {101},
pages = {24-41},
year = {2016},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2015.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X1500107X},
author = {Duílio A.N.S. Silva and Leandro C. Souza and Gustavo H.M.B. Motta},
keywords = {Data mining, Instance selection, Markov geometric diffusion, Large datasets},
}

@InProceedings{10.1007/11538059_91,
author="Han, Hui
and Wang, Wen-Yuan
and Mao, Bing-Huan",
editor="Huang, De-Shuang
and Zhang, Xiao-Ping
and Huang, Guang-Bin",
title="Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning",
booktitle="Advances in Intelligent Computing",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="878--887",
isbn="978-3-540-31902-3"
}

@article{smote,
author = {Chawla, Nitesh and Bowyer, Kevin and Hall, Lawrence and Kegelmeyer, W.},
year = {2002},
month = {06},
pages = {321-357},
title = {SMOTE: Synthetic Minority Over-sampling Technique},
volume = {16},
journal = {J. Artif. Intell. Res. (JAIR)},
doi = {10.1613/jair.953}
}

@article{YenCluster,
author = {Yen, Show-Jane and Lee, Yue-Shi},
year = {2006},
month = {01},
pages = {5718-5727},
title = {Cluster-based Under-sampling Approaches for Imbalanced Data Distributions},
volume = {36},
journal = {Expert Systems with Applications},
doi = {10.1016/j.eswa.2008.06.108}
}

@inproceedings{adasyn,
author = {He, Haibo and Bai, Yang and Garcia, Edwardo and Li, Shutao},
year = {2008},
month = {07},
pages = {1322 - 1328},
title = {ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning},
journal = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2008.4633969}
}

@inproceedings{HempstalkOne,
author = {Hempstalk, Kathryn and Frank, Eibe and Witten, Ian},
year = {2008},
month = {09},
pages = {},
title = {One-Class Classification by Combining Density and Class Probability Estimation},
isbn = {978-3-540-87478-2},
journal = {The European Conference on Machine and Learning and Principles and Practice of Knowledge Discovery in Database},
doi = {10.1007/978-3-540-87479-9_51}
}

@InProceedings{10.1007/978-3-540-87479-9_51,
author="Hempstalk, Kathryn
and Frank, Eibe
and Witten, Ian H.",
editor="Daelemans, Walter
and Goethals, Bart
and Morik, Katharina",
title="One-Class Classification by Combining Density and Class Probability Estimation",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="505--519",
isbn="978-3-540-87479-9"
}

@article{SHIN2005395,
title = {One-class support vector machines—an application in machine fault detection and classification},
journal = {Computers & Industrial Engineering},
volume = {48},
number = {2},
pages = {395-408},
year = {2005},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2005.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0360835205000100},
author = {Hyun Joon Shin and Dong-Hwan Eom and Sung-Shick Kim},
keywords = {Machine fault diagnosis, Support vector machines, One-class classification, Artificial neural networks, Multilayer perception},
abstract = {Fast incipient machine fault diagnosis is becoming one of the key requirements for economical and optimal process operation management. Artificial neural networks have been used to detect machine faults for a number of years and shown to be highly successful in this application area. This paper presents a novel test technique for machine fault detection and classification in electro-mechanical machinery from vibration measurements using one-class support vector machines (SVMs). In order to evaluate one-class SVMs, this paper examines the performance of the proposed method by comparing it with that of multilayer perception, one of the artificial neural network techniques, based on real benchmarking data.}
}

@inproceedings{ErtekinSeyda,
author = {Ertekin, Seyda and Huang, Jian and Bottou, Léon and Giles, C.},
year = {2007},
month = {01},
pages = {127-136},
title = {Learning on the border: Active learning in imbalanced data classification},
journal = {International Conference on Information and Knowledge Management, Proceedings},
doi = {10.1145/1321440.1321461}
}

@Article{vanderPutten2004,
author={van der Putten, Peter
and van Someren, Maarten},
title={A Bias-Variance Analysis of a Real World Learning Problem: The CoIL Challenge 2000},
journal={Machine Learning},
year={2004},
month={Oct},
day={01},
volume={57},
number={1},
pages={177-195},
issn={1573-0565},
doi={10.1023/B:MACH.0000035476.95130.99},
url={https://doi.org/10.1023/B:MACH.0000035476.95130.99}
}

@inproceedings{DunjaMarko,
author = {Mladenić, Dunja and Grobelnik, Marko},
year = {1999},
month = {01},
pages = {258-267},
title = {Feature Selection for Unbalanced Class Distribution and Naive Bayes.}
}

@article{10.5555/944919.944974,
author = {Forman, George},
title = {An Extensive Empirical Study of Feature Selection Metrics for Text Classification},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {1289–1305},
numpages = {17}
}

@article{10.1145/1007730.1007741,
author = {Zheng, Zhaohui and Wu, Xiaoyun and Srihari, Rohini},
title = {Feature Selection for Text Categorization on Imbalanced Data},
year = {2004},
issue_date = {June 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/1007730.1007741},
doi = {10.1145/1007730.1007741},
journal = {SIGKDD Explor. Newsl.},
month = jun,
pages = {80–89},
numpages = {10}
}

@InProceedings{10.1007/978-3-540-75175-5_30,
author="Biesiada, Jacek
and Duch, Wlodzis{\l}aw",
editor="Kurzynski, Marek
and Puchala, Edward
and Wozniak, Michal
and Zolnierek, Andrzej",
title="Feature Selection for High-Dimensional Data --- A Pearson Redundancy Based Filter",
booktitle="Computer Recognition Systems 2",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="242--249",
isbn="978-3-540-75175-5"
}

@article{MALDONADO20092208,
title = {A wrapper method for feature selection using Support Vector Machines},
journal = {Information Sciences},
volume = {179},
number = {13},
pages = {2208-2217},
year = {2009},
note = {Special Section on High Order Fuzzy Sets},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2009.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0020025509000917},
author = {Sebastián Maldonado and Richard Weber},
keywords = {Feature selection, Wrapper methods, Classification, Support Vector Machines, Mathematical programming},
}

@article{10.1016/j.compeleceng.2013.11.024,
author = {Chandrashekar, Girish and Sahin, Ferat},
title = {A Survey on Feature Selection Methods},
year = {2014},
issue_date = {January, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {1},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2013.11.024},
doi = {10.1016/j.compeleceng.2013.11.024},
journal = {Comput. Electr. Eng.},
month = jan,
pages = {16–28},
numpages = {13}
}

@article{PEREIRA2016634,
title = {The Logistic Lasso and Ridge Regression in Predicting Corporate Failure},
journal = {Procedia Economics and Finance},
volume = {39},
pages = {634-641},
year = {2016},
note = {3rd GLOBAL CONFERENCE on BUSINESS, ECONOMICS, MANAGEMENT and TOURISM},
issn = {2212-5671},
doi = {https://doi.org/10.1016/S2212-5671(16)30310-0},
url = {https://www.sciencedirect.com/science/article/pii/S2212567116303100},
author = {Jose Manuel Pereira and Mario Basto and Amelia Ferreira da Silva},
keywords = {Corporate Bankruptcy, Prediction Models, Lasso, Ridge Regression},
}

@article{MELKUMOVA2017746,
title = {Comparing Ridge and LASSO estimators for data analysis},
journal = {Procedia Engineering},
volume = {201},
pages = {746-755},
year = {2017},
note = {3rd International Conference “Information Technology and Nanotechnology", ITNT-2017, 25-27 April 2017, Samara, Russia},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.09.615},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817341474},
author = {L.E. Melkumova and S.Ya. Shatskikh},
keywords = {linear regression, Ridge regression, LASSO, cross-validation},
}

@article{HiroshiMotodaLiu,
author = {Motoda, Hiroshi and Liu, Huan},
year = {2002},
month = {01},
pages = {67-72},
title = {Feature selection, extraction and construction},
volume = {5},
journal = {Communication of IICM (Institute of Information and Computing Machinery, Taiwan)}
}

@inproceedings{MenaLuisGonzalezJesus,
author = {Mena, Luis and Gonzalez, Jesus},
year = {2006},
month = {01},
pages = {574-579},
title = {Machine Learning for Imbalanced Datasets: Application in Medical Diagnostic.},
volume = {2006},
journal = {FLAIRS 2006 - Proceedings of the Nineteenth International Florida Artificial Intelligence Research Society Conference}
}

@INPROCEEDINGS{Quinlan96bagging,
    author = {J. R. Quinlan},
    title = {Bagging, Boosting, and C4.5},
    booktitle = {In Proceedings of the Thirteenth National Conference on Artificial Intelligence},
    year = {1996},
    pages = {725--730},
    publisher = {AAAI Press}
}

@article{adaboost,
author = {Chengsheng, Tu and Huacheng, Liu and Bing, Xu},
year = {2017},
month = {01},
pages = {00222},
title = {AdaBoost typical Algorithm and its application research},
volume = {139},
journal = {MATEC Web of Conferences},
doi = {10.1051/matecconf/201713900222}
}

@article{LangarizadehMostafa,
author = {Langarizadeh, Mostafa and Moghbeli, Fateme},
year = {2016},
month = {10},
pages = {364},
title = {Applying Naive Bayesian Networks to Disease Prediction: a Systematic Review},
volume = {24},
journal = {Acta Informatica Medica},
doi = {10.5455/aim.2016.24.364-369}
}

@article{forest,
author = {Bader-El-Den, Mohamed and Teitei, Eleman and Perry, Todd},
year = {2018},
month = {11},
pages = {1-10},
title = {Biased Random Forest For Dealing With the Class Imbalance Problem},
volume = {PP},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
doi = {10.1109/TNNLS.2018.2878400}
}

@article{NahmFrancis,
author = {Nahm, Francis},
year = {2016},
month = {02},
pages = {8},
title = {Nonparametric statistical tests for the continuous data: The basic concept and the practical use},
volume = {69},
journal = {Korean Journal of Anesthesiology},
doi = {10.4097/kjae.2016.69.1.8}
}

@article{10.1080/10485252.2017.1404598,
author = {Yoonsuh Jung},
title = {Multiple predicting K-fold cross-validation for model selection},
journal = {Journal of Nonparametric Statistics},
volume = {30},
number = {1},
pages = {197-215},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/10485252.2017.1404598},
}

@article{reliefart,
author = {Kononenko, Igor and Šimec, Edvard and Robnik-Sikonja, Marko},
year = {1997},
month = {01},
pages = {39-55},
title = {Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF},
volume = {7},
journal = {Applied Intelligence},
doi = {10.1023/A:1008280620621}
}

@article{URBANOWICZ2018189,
title = {Relief-based feature selection: Introduction and review},
journal = {Journal of Biomedical Informatics},
volume = {85},
pages = {189-203},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418301400},
author = {Ryan J. Urbanowicz and Melissa Meeker and William {La Cava} and Randal S. Olson and Jason H. Moore},
keywords = {Feature selection, Feature interaction, Feature weighting, Filter, ReliefF, Epistasis},
}

@incollection{KIRA1992249,
title = {A Practical Approach to Feature Selection},
editor = {Derek Sleeman and Peter Edwards},
booktitle = {Machine Learning Proceedings 1992},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {249-256},
year = {1992},
isbn = {978-1-55860-247-2},
doi = {https://doi.org/10.1016/B978-1-55860-247-2.50037-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558602472500371},
author = {Kenji Kira and Larry A. Rendell},
}

@article{anovavariance,
title = {Analysis of Variance},
booktitle = {circulation},
pages = {115–121},
month = {06},
year = {2008},
author = {Martin G. Larson},
doi = {https://doi.org/10.1161/CIRCULATIONAHA.107.654335},
}

@article{KumarMukeshRath,
author = {Kumar, Mukesh and Rath, Nitish and Swain, Amitav and Rath, Santanu},
year = {2015},
month = {12},
pages = {301-310},
title = {Feature Selection and Classification of Microarray Data using MapReduce based ANOVA and K-Nearest Neighbor},
volume = {54},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2015.06.035}
}

@InProceedings{10.1007/978-3-540-39964-3_62,
author="Guo, Gongde
and Wang, Hui
and Bell, David
and Bi, Yaxin
and Greer, Kieran",
editor="Meersman, Robert
and Tari, Zahir
and Schmidt, Douglas C.",
title="KNN Model-Based Approach in Classification",
booktitle="On The Move to Meaningful Internet Systems 2003: CoopIS, DOA, and ODBASE",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="986--996",
isbn="978-3-540-39964-3"
}

@article{li2018feature,
title={Feature selection: A data perspective},
author={Li, Jundong and Cheng, Kewei and Wang, Suhang and Morstatter, Fred and Trevino, Robert P and Tang, Jiliang and Liu, Huan},
journal={ACM Computing Surveys (CSUR)},
volume={50},
number={6},
pages={94},
year={2018},
publisher={ACM}
}

@article{reliefbased,
title={Relief-based feature selection: Introduction and review. J Biomed Inform},
author={Urbanowicz RJ, Meeker M, La Cava W, Olson RS, Moore JH},
journal={ACM Computing Surveys (CSUR)},
pages="189--203",
year={2018},
publisher={J Biomed Inform}
}

@Article{jcp1010011,
AUTHOR = {Ahsan, Mostofa and Gomes, Rahul and Chowdhury, Md. Minhaz and Nygard, Kendall E.},
TITLE = {Enhancing Machine Learning Prediction in Cybersecurity Using Dynamic Feature Selector},
JOURNAL = {Journal of Cybersecurity and Privacy},
VOLUME = {1},
YEAR = {2021},
NUMBER = {1},
PAGES = {199--218},
URL = {https://www.mdpi.com/2624-800X/1/1/11},
ISSN = {2624-800X},
DOI = {10.3390/jcp1010011}
}

@book{RaschkaMirjalili2019,  
address = {Birmingham, UK},  
author = {Raschka, Sebastian and Mirjalili, Vahid},  
edition = {3},  
isbn = {978-1789955750},   
publisher = {Packt Publishing},  
title = {{Python Machine Learning, 3rd Ed.}},  
year = {2019}  
}

@book{domański2001metody,
title={Metody statystyczne: teoria i zadania},
author={Doma{\'n}ski, Cz.},
isbn={9788371714818},
url={https://books.google.pl/books?id=dirWXwAACAAJ},
year={2001},
publisher={Wydawnictwo Uniwersytetu {\L}{\'o}dzkiego}
}

@article{hommelcomp,
author = {Chen, Shi-Yi and Feng, Zhe and Yi, Xiaolian},
year = {2017},
month = {06},
pages = {1725-1729},
title = {A general introduction to adjustment for multiple comparisons},
volume = {9},
journal = {Journal of Thoracic Disease},
doi = {10.21037/jtd.2017.05.34}
}

@inproceedings{fastdecisiontreelearning,
author = {Su, Jiang and Zhang, Harry},
title = {A Fast Decision Tree Learning Algorithm},
year = {2006},
isbn = {9781577352815},
publisher = {AAAI Press},
booktitle = {Proceedings of the 21st National Conference on Artificial Intelligence - Volume 1},
pages = {500–505},
numpages = {6},
location = {Boston, Massachusetts},
series = {AAAI'06}
}

@misc{jundongl, title={jundongl/scikit-feature}, url={https://github.com/jundongl/scikit-feature}, journal={GitHub - Scykit-feature}, author={Jundongl}} 

@misc{ulb_2018, title={Credit Card Fraud Detection}, url={https://www.kaggle.com/mlg-ulb/creditcardfraud}, journal={Kaggle}, author={ULB, Machine Learning Group -}, year={2018}, month={Mar}}

@misc{scikit_k_fold, title={sklearn model_selection KFold}, url={https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html}, journal={scikit}}

@misc{scikit_robust, title={sklearn preprocessing RobustScaler}, url={https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html}, journal={scikit}}

@misc{scikit_f_class, title={sklearn feature_selection f_classif}, url={https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html}, journal={scikit}}

@misc{scikit_chi2, title={sklearn feature_selection chi2}, url={https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html}, journal={scikit}}

@misc{scikit_m_i_classif, title={sklearn feature_selection mutual_info_classif}, url={https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html}, journal={scikit}}

@misc{mungo, title={sklearn-relief}, url={https://gitlab.com/moongoal/sklearn-relief}, journal={GitLab - sklearn-relief}, author={Mungo, Alfredo}}

@misc{pandascorr, title={Python: Pandas DataFrame.corr()}, url={https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html}, journal={pandas}, year={2020}, month={Apr}}

@misc{portoseguros, title={Porto Seguros Safe Driver Prediction}, url={https://www.kaggle.com/c/porto-seguro-safe-driver-prediction}, journal={Kaggle}}

@misc{scikitmakeclass, title={sklearn datasets make_classification}, url={https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html}, journal={scikit}}

@misc{scikitlabelenc, title={sklearn Preprocessing LabelEncoder}, url={https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html}, journal={scikit}}

@misc{learning_2016, title={Mushroom Classification}, url={https://www.kaggle.com/uciml/mushroom-classification}, journal={Kaggle}, author={Learning, UCI Machine}, year={2016}, month={Dec}}

@misc{sci2s, title={KEEL: Software tool. Evolutionary algorithms for Data Mining}, url={https://sci2s.ugr.es/keel/imbalanced.php}, journal={SCI2S}}

@misc{kumar_2020, title={Health Insurance Cross Sell Prediction }, url={https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction}, journal={Kaggle}, author={Kumar, Anmol}, year={2020}, month={Sep}}
